# ğŸ“Š Pipeline de Dados com Azure Databricks e Data Factory

Este projeto demonstra a criaÃ§Ã£o e orquestraÃ§Ã£o de pipelines de dados na nuvem utilizando o **Azure Databricks** e o **Azure Data Factory (ADF)**. O objetivo Ã© ilustrar como essas ferramentas podem ser integradas para orquestrar transformaÃ§Ãµes e cargas de dados em um ambiente escalÃ¡vel na nuvem.

## ğŸš€ VisÃ£o Geral

A soluÃ§Ã£o desenvolvida envolve:

- **Azure Data Factory**: ResponsÃ¡vel pela orquestraÃ§Ã£o das tarefas ETL, agendamento de execuÃ§Ãµes e gerenciamento do fluxo dos dados.
- **Azure Databricks**: Utilizado para o processamento e transformaÃ§Ã£o de dados, com notebooks escritos em **Scala**, linguagem principal do projeto.

> ğŸ“ TambÃ©m foram incluÃ­das versÃµes dos notebooks em **Python** com o propÃ³sito de demonstrar familiaridade com a linguagem, embora a execuÃ§Ã£o original tenha sido realizada em Scala.

## ğŸ› ï¸ Tecnologias Utilizadas

- [Azure Data Factory](https://azure.microsoft.com/pt-br/services/data-factory/)
- [Azure Databricks](https://azure.microsoft.com/pt-br/services/databricks/)
- [Apache Spark](https://spark.apache.org/) com linguagem **Scala**
- [Scala](https://www.scala-lang.org/)
- [Python](https://www.python.org/) *(demonstrativo complementar)*

## ğŸ“ Estrutura do RepositÃ³rio

```bash
pipeline-databricks-azure/
â”œâ”€â”€ factory/                # Artefatos do Azure Data Factory (pipelines, triggers)
â”œâ”€â”€ linkedService/          # ConfiguraÃ§Ãµes de conexÃµes (Linked Services)
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ scala/              # Notebooks executados em Scala
â”‚   â””â”€â”€ python/             # Notebooks traduzidos para Python (demonstraÃ§Ã£o)
â”œâ”€â”€ pipeline/               # Pipelines do ADF
â”œâ”€â”€ trigger/                # Triggers de execuÃ§Ã£o (agendamento)
â”œâ”€â”€ publish_config.json     # ConfiguraÃ§Ã£o de publicaÃ§Ã£o do ADF
â”œâ”€â”€ .gitignore              # Arquivos e pastas ignoradas pelo Git
â””â”€â”€ README.md               # DocumentaÃ§Ã£o do projeto
```

## âš™ï¸ Como Executar

1. **Provisionamento de Recursos**:
   - Crie um workspace no **Azure Databricks**.
   - Configure uma instÃ¢ncia do **Azure Data Factory**.

2. **ImportaÃ§Ã£o dos Artefatos**:
   - Importe os notebooks Scala no seu workspace do Databricks.
   - Configure os pipelines, triggers e linked services no ADF.

3. **AtualizaÃ§Ã£o das ConexÃµes**:
   - Atualize os arquivos de `linkedService` com suas credenciais e parÃ¢metros especÃ­ficos do ambiente Azure.

4. **ExecuÃ§Ã£o da Pipeline**:
   - Inicie a execuÃ§Ã£o dos pipelines pelo ADF. Os notebooks Scala serÃ£o acionados conforme definido na orquestraÃ§Ã£o.

## ğŸ’¡ DemonstraÃ§Ãµes com Python

Embora a execuÃ§Ã£o real tenha sido feita em Scala, este repositÃ³rio tambÃ©m inclui notebooks com a traduÃ§Ã£o dos scripts para Python, como forma de demonstrar conhecimento na linguagem e aumentar a portabilidade do projeto.

## ğŸ“Œ ObservaÃ§Ãµes

- Certifique-se de configurar as permissÃµes apropriadas no Databricks e no Data Factory.
- Este projeto serve tanto como material de estudo quanto como demonstraÃ§Ã£o prÃ¡tica de habilidades em engenharia de dados com serviÃ§os Azure.

## ğŸ¤ ColaboraÃ§Ã£o

Este projeto foi desenvolvido em conjunto com a [Alura](https://www.alura.com.br/), como parte de estudos e prÃ¡ticas avanÃ§adas em engenharia de dados com a plataforma Azure.

---

ğŸ“¬ Fique Ã  vontade para abrir *issues* ou sugestÃµes no repositÃ³rio!


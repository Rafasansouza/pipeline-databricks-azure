# üìä Pipeline de Dados com Azure Databricks e Data Factory


Este projeto demonstra a cria√ß√£o e orquestra√ß√£o de pipelines de dados na nuvem utilizando o **Azure Databricks**, o **Azure Data Factory (ADF)** e o **Azure Data Lake Storage (ADLS)**. O objetivo √© ilustrar como essas ferramentas podem ser integradas para orquestrar transforma√ß√µes e cargas de dados em um ambiente escal√°vel na nuvem.

## üìù Descri√ß√£o do projeto

N√≥s, como engenheiros de dados de uma empresa do setor imobili√°rio, fomos respons√°veis por desenvolver um pipeline completo de engenharia de dados. A proposta do projeto √© estruturar um Data Lake, iniciar a ingest√£o dos dados de im√≥veis na camada de entrada (inbound) e, a partir disso, aplicar as transforma√ß√µes necess√°rias para evolu√≠-los atrav√©s das camadas bronze e silver dentro do lake.

Al√©m do processamento, tamb√©m √© fundamental garantir que esse pipeline seja executado automaticamente em intervalos regulares ‚Äî neste caso, a cada hora ‚Äî assegurando que os dados estejam sempre atualizados e prontos para uso.

### Ferramentas utilizadas na empresa

A empresa trabalha com o ecossistema de nuvem da Azure, utilizando o Azure Databricks como ambiente principal para o desenvolvimento e execu√ß√£o dos notebooks. Toda a manipula√ß√£o e transforma√ß√£o dos dados foi feita em Scala, linguagem oficial do projeto. Para a orquestra√ß√£o e agendamento das execu√ß√µes, utilizamos o Azure Data Factory, o que nos permitiu montar uma solu√ß√£o automatizada, escal√°vel e integrada na nuvem.

## üöÄ Vis√£o Geral

A solu√ß√£o desenvolvida envolve:

- **Azure Data Factory**: Respons√°vel pela orquestra√ß√£o das tarefas ETL, agendamento de execu√ß√µes e gerenciamento do fluxo dos dados.
- **Azure Databricks**: Utilizado para o processamento e transforma√ß√£o de dados, com notebooks escritos em **Scala**, linguagem principal do projeto.
- **Azure Data Lake Storage (Gen2)**: Reposit√≥rio utilizado para armazenar os dados brutos e transformados de forma estruturada e escal√°vel.

> üìù Tamb√©m foram inclu√≠das vers√µes dos notebooks em **Python** com o prop√≥sito de demonstrar familiaridade com a linguagem, embora a execu√ß√£o original tenha sido realizada em Scala.

## üõ†Ô∏è Tecnologias Utilizadas

- [Azure Data Factory](https://azure.microsoft.com/pt-br/services/data-factory/)
- [Azure Databricks](https://azure.microsoft.com/pt-br/services/databricks/)
- [Azure Data Lake Storage Gen2](https://learn.microsoft.com/pt-br/azure/storage/data-lake-storage/)
- [Apache Spark](https://spark.apache.org/) com linguagem **Scala**
- [Scala](https://www.scala-lang.org/)
- [Python](https://www.python.org/) *(demonstrativo complementar)*

## üìÅ Estrutura do Reposit√≥rio

```bash
pipeline-databricks-azure/
‚îú‚îÄ‚îÄ factory/                # Artefatos do Azure Data Factory (pipelines, triggers)
‚îú‚îÄ‚îÄ linkedService/          # Configura√ß√µes de conex√µes (Linked Services)
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îú‚îÄ‚îÄ scala/              # Notebooks executados em Scala
‚îÇ   ‚îî‚îÄ‚îÄ python/             # Notebooks traduzidos para Python (demonstra√ß√£o)
‚îú‚îÄ‚îÄ pipeline/               # Pipelines do ADF
‚îú‚îÄ‚îÄ trigger/                # Triggers de execu√ß√£o (agendamento)
‚îú‚îÄ‚îÄ publish_config.json     # Configura√ß√£o de publica√ß√£o do ADF
‚îú‚îÄ‚îÄ .gitignore              # Arquivos e pastas ignoradas pelo Git
‚îî‚îÄ‚îÄ README.md               # Documenta√ß√£o do projeto
```

## ‚öôÔ∏è Como Executar

### 1. Provisionamento de Recursos no Azure

- **Grupo de Recursos**: Crie um grupo de recursos para organizar todos os servi√ßos relacionados.
- **Azure Data Lake Storage Gen2**: Configure uma conta de armazenamento para armazenar os dados brutos e processados.
- **Azure Databricks**: Crie um workspace para desenvolvimento e execu√ß√£o dos notebooks.
- **Azure Data Factory**: Configure uma inst√¢ncia para orquestra√ß√£o dos pipelines.

### 2. Configura√ß√£o do Azure Data Factory (ADF)

- **Linked Services**: Defina conex√µes com o Azure Databricks e o Azure Data Lake Storage.
- **Datasets**: Configure os conjuntos de dados que ser√£o utilizados nos pipelines.
- **Pipelines**: Crie os pipelines que orquestrar√£o as tarefas de ETL.
- **Triggers**: Estabele√ßa gatilhos para execu√ß√£o autom√°tica dos pipelines conforme necessidade.

### 3. Desenvolvimento no Azure Databricks

- **Importa√ß√£o de Notebooks**: Importe os notebooks desenvolvidos em Scala para o workspace do Databricks.
- **Configura√ß√£o de Clusters**: Configure os clusters necess√°rios para execu√ß√£o dos notebooks.
- **Testes Locais**: Realize testes locais para validar o funcionamento dos notebooks antes da integra√ß√£o com o ADF.

### 4. Integra√ß√£o entre ADF e Databricks

- **Atividades de Notebook**: No ADF, adicione atividades que executem os notebooks do Databricks dentro dos pipelines.
- **Par√¢metros**: Configure par√¢metros necess√°rios para a execu√ß√£o din√¢mica dos notebooks.
- **Valida√ß√£o**: Teste a integra√ß√£o para garantir que os notebooks sejam executados corretamente via ADF.

### 5. Execu√ß√£o e Monitoramento

- **Execu√ß√£o dos Pipelines**: Inicie a execu√ß√£o dos pipelines manualmente ou via triggers configurados.
- **Monitoramento**: Utilize as ferramentas de monitoramento do ADF para acompanhar a execu√ß√£o e identificar poss√≠veis falhas.
- **Logs e Diagn√≥stico**: Analise os logs gerados para diagn√≥stico e resolu√ß√£o de problemas.

### 6. Manuten√ß√£o e Atualiza√ß√µes

- **Versionamento**: Utilize o GitHub para versionar os notebooks e pipelines, facilitando o controle de mudan√ßas.
- **Documenta√ß√£o**: Mantenha a documenta√ß√£o atualizada para facilitar futuras manuten√ß√µes e onboarding de novos colaboradores.
- **Melhorias Cont√≠nuas**: Avalie constantemente o desempenho dos pipelines e notebooks, implementando melhorias conforme necess√°rio.


## üí° Demonstra√ß√µes com Python

Embora a execu√ß√£o real tenha sido feita em Scala, este reposit√≥rio tamb√©m inclui notebooks com a tradu√ß√£o dos scripts para Python, como forma de demonstrar conhecimento na linguagem e aumentar a portabilidade do projeto.

## üìå Observa√ß√µes

- Certifique-se de configurar as permiss√µes apropriadas no Databricks e no Data Factory.
- Este projeto serve tanto como material de estudo quanto como demonstra√ß√£o pr√°tica de habilidades em engenharia de dados com servi√ßos Azure.

## ü§ù Colabora√ß√£o

Este projeto foi desenvolvido em conjunto com a [Alura](https://www.alura.com.br/), como parte de estudos e pr√°ticas avan√ßadas em engenharia de dados com a plataforma Azure.

---

üì¨ Fique √† vontade para abrir *issues* ou sugest√µes no reposit√≥rio!

